% !TeX spellcheck=en_US

\section{Experiment Result}\label{Experiment Result}
In this section, we conduct extensive experiments on dataset which is generated 
randomly based on the information of some soccers player and their careers to 
evaluate the proposed methods for storing, indexing and query processing in scope 
query we porposed.

\subsection{Dataset}
We use the basic dataset in which per line describes that a soccker player serve a team
at a short time interval. Besides, the basic dataset also contains some  extra information 
such as the birthday of player and the his position in a soccer team and so on. The 
structure of the dataset is described in Table \ref{basic_data}.

\begin{table}
	\centering
	\caption{Soccer player information example}
	\label{basic_data}
	\begin{small}
		\begin{tabular}{p{1.6cm}|p{2.5cm}|p{1.2cm}|p{1.3cm}|p{1.7cm}|p{1.5cm}|p{1.5cm}}
			\hline
			Player & Team & Position & Birthday & Birth Place & Start Year & End Year\\ \hline
			Ant & Houston Texans & DB & 1991 & Florida & 2016 & 2020 \\\hline
			A.J. Edds & New York Jets & LB & 1987 & Iowa & 2014 & 2018 \\\hline
			Korey Hall & Chicago Bears & DB & 1983 & Boise State & 2014 & 2015 \\\hline
		\end{tabular}
	\end{small}
\end{table}

In order to comprehensively display the performance of the proposed n methods for different query, 
we extend the basic dataset generating new datasets which contains more entries about different 
soccer players. Different size of new generated datasets are described in Table \ref{gen_data}. Note that 
the number of players in generated dataset is different in multiple experiments because of the randomness 
of generation algorithms.

\begin{table}
	\centering
	\caption{Generated Dataset Description}
	\label{gen_data}
	\begin{small}
		\begin{tabular}{p{4cm}|p{3cm}}
			\hline
			number of fact  & number of entity \\\hline
			100,000 & 25,497 \\\hline
			1,000,000 &  253,784 \\\hline
			10,000,000 & 2,540,461 \\\hline
		\end{tabular}
	\end{small}
\end{table}


We implement storing, indexing and four kinds of basic queries processing as well as generating new dataset in Python.
To make comparison, we use non-index query processing as a baseline, i.e., for the several basic kinds of queries, the 
storage model is directly accessed and sequential scans are acrried out. And Then we use our hash methods in  memory 
and build index for time interval to process queries. The experiments are conducted on a PC with Intel Core i7-7700K 
CPU 4.20GHz Core 8, 16GB memory and 910GB disk on Linux version 4.14.3-1-ARCH.

\subsection{Baseline}
In this part, we sum the time of four kinds of queries which processing 10 queries respectively. As show in Fig.
\ref{baseline}, the cost in queries have a sharp increase sadly following the size of dataset increasing. The 
ticks in X axis denote the logarithms of low 10. It is obviously that the queries suffer poor performance in 
baseline.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\textwidth]{pic/baseline.eps}\\
	\caption{Baseline: Four kinds of queries time}
	\label{baseline}
\end{figure}

\subsection{Hash-based}
After building hash index for players and teams, and loading the relation existing in time interval into memory, 
we evaluate the same benchmark as well as in method of baseline. The trend in Fig.\ref{time} looks similar among four 
kinds of queries, but you should note that the triks in y axis have droped down less than one second from dozens of 
seconds in query HF, RO, RH. But for the query FF processing, the cost is stil so high because of if we want to get 
what has happed in a time interval, we still need going through all the entries between players and teams.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\textwidth]{pic/time_idx.eps}\\
	\caption{Hash-based: Four kinds of queries time}
	\label{time}
\end{figure}

\subsection{Index for Time Interval}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{pic/csparql_t_index.eps}\\
	\caption{Four kinds of queries index}
	\label{index_p}
\end{figure}

As show in Fig.\ref{index_p}, we build two-layer based index strategy for time interval ${(Start Time_x, End Time_y)}$.
The first layer index is build for $Start Time_x$ in time interval using sequential index in Fig.\ref{index_p}. The 
second layer is for the $End Time_x$. After building index for time interval, we even just use easily binary search method
which conducts a significant reduction in query cost of method RH as show in following. The time of building index is show 
in Fig.\ref{index}. Because of logarithms in the horizontal axis following the nolinear increasement in number of dataset, 
the trend of Fig.\ref{index} look like a exponential type. It is a linear increasement actully.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\textwidth]{pic/index.eps}\\
	\caption{Four kinds of queries index}
	\label{index}
\end{figure}


We just build sequential index easily to solve the poor performance of RH query in the before method. The performance 
of RH query gets a lot improve which reduce time cost from 100-plus seconds to less than one second as show in Fig.
\ref{time-idx}. For showing the  extensibility of our methods, we add the four group test queries which have 10, 100, 
1000, 10000 entries respectively. In the extensibility experiment, we use the logarithms in the horizontal axis following
the nolinear increasement in number of queries. Therefore even if the trend in Fig.\ref{query} looks like exponential type, 
it is stll linear time increasement. Besides the cost in queries is still so slow that we can get the results of queries less
than one second even processing 10000 queries.
\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\textwidth]{pic/time.eps}\\
	\caption{Index-time-interval: Four kinds of queries time}
	\label{time-idx}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\textwidth]{pic/query.eps}\\
	\caption{Four kinds of queries time}
	\label{query}
\end{figure}
Moreover we summary the running time of four basic query in different size datasets using line chart. Due to the high time cost 
in baseline, we just sum the 10 queries running time. As show in Fig.\ref{combine}, it is obviously the baseline need far more time
than the other methods. The method of hash-based performs wonderful except in query RH. As described before,  we still need going 
through all the entries between players and teams to get the cluster of event in a given time interval. After we build sequential
index for time interval, this predicament in query RH has been solved.


\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\textwidth]{pic/combine.eps}\\
	\caption{Four kinds of queries time}
	\label{combine}
\end{figure}

% \begin{figure}[H]
% \centering
% 	\subfigure[index-p] {
% 		\begin{minipage}{7cm}
% 		\center
% 		\includegraphics[scale=0.5]{pic/csparql_t_index.eps}
% 		\end{minipage}
% 	}
% 	\subfigure[index] {
% 		\begin{minipage}{7cm}
% 		\center
% 		\includegraphics[scale=0.4]{pic/index.eps}
% 		\end{minipage}
% 	}
% 	\caption{name of the figure}
% 	\label{index}    
% \end{figure}[H]
